"""
高频预测系统架构
数据源层 -> 流处理层 -> 特征工程层 -> 模型层 -> 决策层
"""
┌─────────────────────────────────────────────────────────────┐
│                      数据源层                                │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐           │
│  │ Alpaca  │ │Polygon  │ │  IB API │ │  新闻源  │           │
│  │ WebSocket││ WebSocket││         │ │         │           │
│  └─────────┘ └─────────┘ └─────────┘ └─────────┘           │
│          ↓           ↓           ↓           ↓              │
└─────────────────────────────────────────────────────────────┘
                               ↓
┌─────────────────────────────────────────────────────────────┐
│                   流处理层 (Apache Kafka)                    │
│  ┌─────────────────────────────────────────────────────┐    │
│  │           Kafka Topics:                             │    │
│  │   • tick_data_raw   • orderbook_raw                 │    │
│  │   • news_raw        • processed_features            │    │
│  └─────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────┘
                               ↓
┌─────────────────────────────────────────────────────────────┐
│                特征工程层 (Apache Flink)                     │
│  ┌─────────────────────────────────────────────────────┐    │
│  │  Flink Jobs:                                        │    │
│  │   • 订单簿特征提取    • 技术指标计算                  │    │
│  │   • 新闻情感分析     • 高频特征生成                  │    │
│  └─────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────┘
                               ↓
┌─────────────────────────────────────────────────────────────┐
│                     模型推理层                               │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐           │
│  │ LOB模型 │ │时间序列 │ │集成模型 │ │风控模型 │           │
│  │ (CNN/   │ │(LSTM/   │ │(XGBoost)│ │         │           │
│  │ Transformer)│GRU)   │ │         │ │         │           │
│  └─────────┘ └─────────┘ └─────────┘ └─────────┘           │
└─────────────────────────────────────────────────────────────┘
                               ↓
┌─────────────────────────────────────────────────────────────┐
│                     交易决策层                               │
│  ┌─────────────────────────────────────────────────────┐    │
│  │  信号生成 → 仓位管理 → 订单执行 → 绩效监控            │    │
│  └─────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────┘

# data_collector.py
import asyncio
import json
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import numpy as np

class DataCollector:
    """统一数据收集器，支持多个数据源"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.kafka_producer = None  # Kafka生产者
        self.setup_kafka()
        
    def setup_kafka(self):
        """设置Kafka生产者"""
        from kafka import KafkaProducer
        
        self.kafka_producer = KafkaProducer(
            bootstrap_servers=self.config['kafka']['bootstrap_servers'],
            value_serializer=lambda v: json.dumps(v).encode('utf-8'),
            key_serializer=lambda v: v.encode('utf-8') if v else None,
            acks='all',
            retries=3
        )
        
    # ==================== Alpaca数据收集 ====================
    async def collect_alpaca_data(self, symbols: List[str]):
        """收集Alpaca实时数据"""
        import alpaca_trade_api as tradeapi
        from alpaca_trade_api.stream2 import StreamConn
        
        # 设置连接
        conn = StreamConn(
            key_id=self.config['alpaca']['api_key'],
            secret_key=self.config['alpaca']['secret_key'],
            base_url=self.config['alpaca']['base_url']
        )
        
        @conn.on(r'^AM\.')
        async def on_minute_bar(conn, channel, data):
            """处理分钟K线数据"""
            kafka_data = {
                'timestamp': data.timestamp,
                'symbol': data.symbol,
                'open': data.open,
                'high': data.high,
                'low': data.low,
                'close': data.close,
                'volume': data.volume,
                'data_type': 'minute_bar'
            }
            self.send_to_kafka('tick_data_raw', kafka_data, key=data.symbol)
            
        @conn.on(r'^Q\.')
        async def on_quote(conn, channel, data):
            """处理报价数据"""
            kafka_data = {
                'timestamp': datetime.now().isoformat(),
                'symbol': data.symbol,
                'bid_price': data.bidprice,
                'bid_size': data.bidsize,
                'ask_price': data.askprice,
                'ask_size': data.asksize,
                'data_type': 'quote'
            }
            self.send_to_kafka('tick_data_raw', kafka_data, key=data.symbol)
            
        @conn.on(r'^T\.')
        async def on_trade(conn, channel, data):
            """处理交易数据"""
            kafka_data = {
                'timestamp': data.timestamp,
                'symbol': data.symbol,
                'price': data.price,
                'size': data.size,
                'exchange': data.exchange,
                'data_type': 'trade'
            }
            self.send_to_kafka('tick_data_raw', kafka_data, key=data.symbol)
        
        # 订阅数据
        channels = [f"AM.{symbol}" for symbol in symbols] + \
                   [f"Q.{symbol}" for symbol in symbols] + \
                   [f"T.{symbol}" for symbol in symbols]
        
        await conn.subscribe(channels)
        await conn.run()
        
    # ==================== 订单簿数据收集 ====================
    async def collect_orderbook_data(self, symbols: List[str], depth: int = 10):
        """收集限价订单簿数据"""
        # 使用Polygon.io获取订单簿数据（支持美股）
        import websocket
        import threading
        import time
        
        class OrderBookWebSocket:
            def __init__(self, api_key: str, symbols: List[str]):
                self.api_key = api_key
                self.symbols = symbols
                self.ws = None
                
            def on_message(self, ws, message):
                data = json.loads(message)
                if data[0]['ev'] == 'status':
                    return
                    
                # 处理订单簿更新
                orderbook_data = self.parse_orderbook(data[0])
                self.send_to_kafka('orderbook_raw', orderbook_data, key=orderbook_data['symbol'])
                
            def parse_orderbook(self, data: Dict) -> Dict:
                """解析订单簿数据"""
                return {
                    'timestamp': datetime.now().isoformat(),
                    'symbol': data['sym'],
                    'bid_prices': data.get('b', [])[:10],  # 买1-买10价格
                    'bid_sizes': data.get('b', [])[:10],   # 买1-买10数量
                    'ask_prices': data.get('a', [])[:10],  # 卖1-卖10价格
                    'ask_sizes': data.get('a', [])[:10],   # 卖1-卖10数量
                    'event_type': data['ev'],
                    'data_type': 'orderbook'
                }
                
            def run(self):
                # Polygon.io WebSocket连接
                ws_url = f"wss://socket.polygon.io/stocks"
                self.ws = websocket.WebSocketApp(
                    ws_url,
                    on_message=self.on_message,
                    on_open=self.on_open
                )
                self.ws.run_forever()
                
            def on_open(self, ws):
                # 认证和订阅
                auth_msg = {"action": "auth", "params": self.api_key}
                ws.send(json.dumps(auth_msg))
                
                # 订阅订单簿数据
                for symbol in self.symbols:
                    sub_msg = {"action": "subscribe", "params": f"Q.{symbol}"}
                    ws.send(json.dumps(sub_msg))
        
        # 启动WebSocket
        ws_client = OrderBookWebSocket(
            api_key=self.config['polygon']['api_key'],
            symbols=symbols
        )
        
        # 在单独线程中运行
        ws_thread = threading.Thread(target=ws_client.run)
        ws_thread.daemon = True
        ws_thread.start()
        
    # ==================== 新闻数据收集 ====================
    def collect_news_data(self):
        """收集新闻和社交媒体数据"""
        import requests
        from textblob import TextBlob
        
        # NewsAPI示例
        def fetch_news(symbol: str):
            url = f"https://newsapi.org/v2/everything"
            params = {
                'q': symbol,
                'apiKey': self.config['newsapi']['api_key'],
                'language': 'en',
                'sortBy': 'publishedAt',
                'pageSize': 10
            }
            
            response = requests.get(url, params=params)
            if response.status_code == 200:
                articles = response.json().get('articles', [])
                
                for article in articles:
                    # 情感分析
                    text = f"{article['title']} {article.get('description', '')}"
                    sentiment = TextBlob(text).sentiment
                    
                    news_data = {
                        'timestamp': article['publishedAt'],
                        'symbol': symbol,
                        'title': article['title'],
                        'source': article['source']['name'],
                        'url': article['url'],
                        'sentiment_polarity': sentiment.polarity,  # -1到1
                        'sentiment_subjectivity': sentiment.subjectivity,  # 0到1
                        'data_type': 'news'
                    }
                    
                    self.send_to_kafka('news_raw', news_data, key=symbol)
                    
        # 定期获取新闻（示例：每5分钟）
        import schedule
        import time
        
        symbols = self.config['symbols']
        for symbol in symbols:
            schedule.every(5).minutes.do(fetch_news, symbol)
            
        while True:
            schedule.run_pending()
            time.sleep(1)
            
    def send_to_kafka(self, topic: str, data: Dict, key: Optional[str] = None):
        """发送数据到Kafka"""
        if self.kafka_producer:
            future = self.kafka_producer.send(
                topic=topic,
                value=data,
                key=key
            )
            # 可选的：等待发送确认
            # future.get(timeout=10)
            
    # ==================== 数据存储 ====================
    def store_to_database(self, data: Dict, collection_name: str):
        """存储数据到数据库（示例使用MongoDB）"""
        from pymongo import MongoClient
        
        client = MongoClient(self.config['mongodb']['uri'])
        db = client[self.config['mongodb']['database']]
        collection = db[collection_name]
        
        # 添加时间戳索引
        collection.create_index([("timestamp", 1)])
        collection.create_index([("symbol", 1), ("timestamp", 1)])
        
        collection.insert_one(data)




        # feature_engineer.py
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.datastream.connectors import FlinkKafkaConsumer, FlinkKafkaProducer
from pyflink.common.serialization import SimpleStringSchema
from pyflink.common.typeinfo import Types
from pyflink.datastream.functions import MapFunction, FlatMapFunction, ProcessFunction
import json
import numpy as np
from typing import List, Tuple
import talib
from collections import deque

class FeatureEngineeringJob:
    """实时特征工程Flink作业"""
    
    def __init__(self):
        self.env = StreamExecutionEnvironment.get_execution_environment()
        
    def create_orderbook_features(self, orderbook_data: Dict) -> Dict:
        """从订单簿数据提取特征"""
        bids = list(zip(orderbook_data['bid_prices'], orderbook_data['bid_sizes']))
        asks = list(zip(orderbook_data['ask_prices'], orderbook_data['ask_sizes']))
        
        # 1. 买卖价差特征
        if bids and asks:
            best_bid = bids[0][0]
            best_ask = asks[0][0]
            spread = best_ask - best_bid
            relative_spread = spread / ((best_ask + best_bid) / 2) if (best_ask + best_bid) > 0 else 0
            
            # 2. 订单簿不平衡度
            total_bid_volume = sum(size for _, size in bids)
            total_ask_volume = sum(size for _, size in asks)
            orderbook_imbalance = (total_bid_volume - total_ask_volume) / \
                                  (total_bid_volume + total_ask_volume + 1e-10)
            
            # 3. 加权中间价
            vwap_bid = sum(price * size for price, size in bids) / total_bid_volume if total_bid_volume > 0 else 0
            vwap_ask = sum(price * size for price, size in asks) / total_ask_volume if total_ask_volume > 0 else 0
            
            # 4. 订单簿深度特征
            depth_levels = [1, 5, 10]  # 不同深度的特征
            depth_features = {}
            for level in depth_levels:
                if len(bids) >= level and len(asks) >= level:
                    bid_depth = sum(size for _, size in bids[:level])
                    ask_depth = sum(size for _, size in asks[:level])
                    depth_features[f'depth_ratio_{level}'] = bid_depth / (ask_depth + 1e-10)
            
            # 5. 价格压力指标
            mid_price = (best_bid + best_ask) / 2
            micro_price = (vwap_bid * total_ask_volume + vwap_ask * total_bid_volume) / \
                          (total_bid_volume + total_ask_volume + 1e-10)
            
            features = {
                'timestamp': orderbook_data['timestamp'],
                'symbol': orderbook_data['symbol'],
                'best_bid': best_bid,
                'best_ask': best_ask,
                'spread': spread,
                'relative_spread': relative_spread,
                'orderbook_imbalance': orderbook_imbalance,
                'vwap_bid': vwap_bid,
                'vwap_ask': vwap_ask,
                'mid_price': mid_price,
                'micro_price': micro_price,
                **depth_features,
                'total_bid_volume': total_bid_volume,
                'total_ask_volume': total_ask_volume
            }
            
            return features
            
        return {}
    
    def create_high_frequency_features(self, tick_data: List[Dict], window_size: int = 100) -> Dict:
        """从高频tick数据提取特征"""
        if len(tick_data) < window_size:
            return {}
            
        prices = [tick['price'] for tick in tick_data[-window_size:]]
        volumes = [tick['size'] for tick in tick_data[-window_size:]]
        timestamps = [tick['timestamp'] for tick in tick_data[-window_size:]]
        
        # 转换为numpy数组
        prices_np = np.array(prices)
        volumes_np = np.array(volumes)
        
        # 1. 收益特征
        returns = np.diff(prices_np) / prices_np[:-1]
        
        # 2. 波动率特征
        realized_volatility = np.sqrt(np.sum(returns**2))
        parkinson_vol = (np.max(prices_np) - np.min(prices_np)) / (4 * np.log(2) * np.mean(prices_np))
        
        # 3. 成交量特征
        volume_velocity = np.mean(np.diff(volumes_np))
        volume_acceleration = np.mean(np.diff(np.diff(volumes_np)))
        
        # 4. 买卖压力
        # 假设有买卖方向信息
        buy_volume = sum(v for i, v in enumerate(volumes) if i % 2 == 0)  # 简化
        sell_volume = sum(v for i, v in enumerate(volumes) if i % 2 == 1)
        buy_sell_ratio = buy_volume / (sell_volume + 1e-10)
        
        # 5. 时间特征
        time_gaps = np.diff([pd.Timestamp(ts).timestamp() for ts in timestamps])
        avg_time_gap = np.mean(time_gaps) if len(time_gaps) > 0 else 0
        
        features = {
            'timestamp': timestamps[-1],
            'mean_return': np.mean(returns) if len(returns) > 0 else 0,
            'std_return': np.std(returns) if len(returns) > 0 else 0,
            'skew_return': pd.Series(returns).skew() if len(returns) > 0 else 0,
            'kurtosis_return': pd.Series(returns).kurtosis() if len(returns) > 0 else 0,
            'realized_volatility': realized_volatility,
            'parkinson_volatility': parkinson_vol,
            'volume_velocity': volume_velocity,
            'volume_acceleration': volume_acceleration,
            'buy_sell_ratio': buy_sell_ratio,
            'avg_time_gap': avg_time_gap,
            'num_ticks': len(tick_data),
            'price_range': np.max(prices_np) - np.min(prices_np),
            'volume_sum': np.sum(volumes_np)
        }
        
        return features
    
    def run(self):
        """运行Flink特征工程作业"""
        # 1. 创建Kafka消费者
        properties = {
            'bootstrap.servers': 'localhost:9092',
            'group.id': 'feature-engineering-group'
        }
        
        orderbook_consumer = FlinkKafkaConsumer(
            'orderbook_raw',
            SimpleStringSchema(),
            properties
        )
        
        tick_consumer = FlinkKafkaConsumer(
            'tick_data_raw',
            SimpleStringSchema(),
            properties
        )
        
        # 2. 处理订单簿数据
        orderbook_stream = self.env \
            .add_source(orderbook_consumer) \
            .map(lambda x: json.loads(x), output_type=Types.PY_DICT) \
            .filter(lambda x: x.get('data_type') == 'orderbook') \
            .map(self.create_orderbook_features, output_type=Types.PY_DICT)
        
        # 3. 处理tick数据（使用滑动窗口）
        class TickWindowFunction(ProcessFunction):
            def __init__(self, window_size: int = 100):
                self.window_size = window_size
                self.tick_windows = {}
                
            def process_element(self, value, ctx):
                symbol = value['symbol']
                if symbol not in self.tick_windows:
                    self.tick_windows[symbol] = deque(maxlen=self.window_size)
                
                self.tick_windows[symbol].append(value)
                
                if len(self.tick_windows[symbol]) >= self.window_size:
                    features = self.create_high_frequency_features(
                        list(self.tick_windows[symbol])
                    )
                    if features:
                        yield json.dumps(features)
        
        tick_stream = self.env \
            .add_source(tick_consumer) \
            .map(lambda x: json.loads(x), output_type=Types.PY_DICT) \
            .filter(lambda x: x.get('data_type') == 'trade') \
            .key_by(lambda x: x['symbol']) \
            .process(TickWindowFunction(window_size=100))
        
        # 4. 合并特征流
        combined_stream = orderbook_stream.union(tick_stream.map(
            lambda x: json.loads(x), output_type=Types.PY_DICT
        ))
        
        # 5. 发送到Kafka
        kafka_producer = FlinkKafkaProducer(
            'processed_features',
            SimpleStringSchema(),
            properties
        )
        
        combined_stream.map(lambda x: json.dumps(x)).add_sink(kafka_producer)
        
        # 6. 执行作业
        self.env.execute("Feature Engineering Job")


        # models.py
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import numpy as np
from typing import Tuple, List
import pandas as pd

class OrderBookDataset(Dataset):
    """订单簿数据集"""
    
    def __init__(self, data_path: str, sequence_length: int = 100, 
                 prediction_horizon: int = 10):
        self.data = pd.read_parquet(data_path)
        self.sequence_length = sequence_length
        self.prediction_horizon = prediction_horizon
        
    def __len__(self):
        return len(self.data) - self.sequence_length - self.prediction_horizon
    
    def __getitem__(self, idx):
        # 获取序列数据
        seq_data = self.data.iloc[idx:idx+self.sequence_length]
        
        # 提取特征和目标
        features = self._extract_features(seq_data)
        target = self._extract_target(seq_data, idx)
        
        return torch.FloatTensor(features), torch.FloatTensor(target)
    
    def _extract_features(self, seq_data: pd.DataFrame) -> np.ndarray:
        """提取订单簿特征"""
        features = []
        
        # 基础订单簿特征
        features.append(seq_data['best_bid'].values.reshape(-1, 1))
        features.append(seq_data['best_ask'].values.reshape(-1, 1))
        features.append(seq_data['spread'].values.reshape(-1, 1))
        features.append(seq_data['orderbook_imbalance'].values.reshape(-1, 1))
        features.append(seq_data['total_bid_volume'].values.reshape(-1, 1))
        features.append(seq_data['total_ask_volume'].values.reshape(-1, 1))
        
        # 深度特征
        for i in range(1, 6):
            if f'depth_ratio_{i}' in seq_data.columns:
                features.append(seq_data[f'depth_ratio_{i}'].values.reshape(-1, 1))
        
        # 合并所有特征
        return np.concatenate(features, axis=1)
    
    def _extract_target(self, seq_data: pd.DataFrame, idx: int) -> np.ndarray:
        """提取预测目标"""
        current_mid = seq_data['mid_price'].iloc[-1]
        future_idx = idx + self.sequence_length + self.prediction_horizon
        
        if future_idx < len(self.data):
            future_mid = self.data['mid_price'].iloc[future_idx]
            # 预测未来价格变化百分比
            return np.array([(future_mid - current_mid) / current_mid])
        
        return np.array([0.0])

class CNNLSTMModel(nn.Module):
    """CNN-LSTM混合模型用于订单簿预测"""
    
    def __init__(self, input_dim: int = 10, hidden_dim: int = 64, 
                 num_layers: int = 2, output_dim: int = 1, 
                 kernel_size: int = 3, dropout: float = 0.2):
        super(CNNLSTMModel, self).__init__()
        
        # CNN层：提取空间特征（不同档位之间的关系）
        self.cnn = nn.Sequential(
            nn.Conv1d(input_dim, 32, kernel_size=kernel_size, padding=1),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Conv1d(32, 64, kernel_size=kernel_size, padding=1),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(dropout)
        )
        
        # LSTM层：提取时间序列特征
        self.lstm = nn.LSTM(
            input_size=64,
            hidden_size=hidden_dim,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0,
            bidirectional=True
        )
        
        # 注意力机制
        self.attention = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, 1)
        )
        
        # 全连接层
        self.fc = nn.Sequential(
            nn.Linear(hidden_dim * 2, 128),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, output_dim)
        )
        
    def forward(self, x):
        # x shape: (batch_size, seq_len, input_dim)
        batch_size, seq_len, input_dim = x.shape
        
        # CNN处理：需要调整为 (batch_size, input_dim, seq_len)
        x_cnn = x.permute(0, 2, 1)
        cnn_out = self.cnn(x_cnn)  # (batch_size, 64, seq_len)
        
        # 调整回LSTM输入格式
        cnn_out = cnn_out.permute(0, 2, 1)  # (batch_size, seq_len, 64)
        
        # LSTM处理
        lstm_out, (hidden, cell) = self.lstm(cnn_out)  # (batch_size, seq_len, hidden_dim*2)
        
        # 注意力机制
        attention_weights = F.softmax(self.attention(lstm_out), dim=1)
        context_vector = torch.sum(attention_weights * lstm_out, dim=1)
        
        # 最终预测
        output = self.fc(context_vector)
        
        return output

class TransformerLOBModel(nn.Module):
    """Transformer模型用于订单簿预测"""
    
    def __init__(self, input_dim: int = 10, d_model: int = 64, 
                 nhead: int = 8, num_layers: int = 4, 
                 dim_feedforward: int = 256, dropout: float = 0.1):
        super(TransformerLOBModel, self).__init__()
        
        # 输入嵌入层
        self.input_projection = nn.Linear(input_dim, d_model)
        
        # 位置编码
        self.pos_encoder = PositionalEncoding(d_model, dropout)
        
        # Transformer编码器
        encoder_layers = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=dim_feedforward,
            dropout=dropout,
            batch_first=True
        )
        self.transformer_encoder = nn.TransformerEncoder(
            encoder_layers,
            num_layers=num_layers
        )
        
        # 输出层
        self.output_layer = nn.Sequential(
            nn.Linear(d_model, 128),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1)
        )
        
    def forward(self, x):
        # x shape: (batch_size, seq_len, input_dim)
        
        # 输入投影
        x = self.input_projection(x)
        
        # 位置编码
        x = self.pos_encoder(x)
        
        # Transformer编码
        transformer_out = self.transformer_encoder(x)
        
        # 取最后一个时间步
        last_output = transformer_out[:, -1, :]
        
        # 最终预测
        output = self.output_layer(last_output)
        
        return output

class PositionalEncoding(nn.Module):
    """Transformer位置编码"""
    
    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)
        
        # 创建位置编码矩阵
        position = torch.arange(max_len).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2) * 
                           (-np.log(10000.0) / d_model))
        
        pe = torch.zeros(max_len, d_model)
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        
        self.register_buffer('pe', pe.unsqueeze(0))
        
    def forward(self, x):
        x = x + self.pe[:, :x.size(1)]
        return self.dropout(x)

class HighFrequencyEnsembleModel:
    """高频预测集成模型"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.models = {}
        self.initialize_models()
        
    def initialize_models(self):
        """初始化多个模型"""
        # 1. 订单簿模型
        self.models['cnn_lstm'] = CNNLSTMModel(
            input_dim=self.config['model']['input_dim'],
            hidden_dim=64,
            num_layers=2
        )
        
        # 2. Transformer模型
        self.models['transformer'] = TransformerLOBModel(
            input_dim=self.config['model']['input_dim'],
            d_model=64,
            nhead=8,
            num_layers=4
        )
        
        # 3. 时间序列模型
        self.models['temporal_cnn'] = TemporalCNN(
            input_dim=self.config['model']['input_dim'],
            num_channels=[32, 64, 128],
            kernel_size=3
        )
        
        # 4. 元模型（集成学习）
        self.meta_model = MetaModel(
            num_base_models=len(self.models),
            hidden_dim=32
        )
        
    def train(self, train_data: pd.DataFrame, val_data: pd.DataFrame):
        """训练集成模型"""
        # 准备数据
        train_dataset = OrderBookDataset(
            data=train_data,
            sequence_length=self.config['data']['sequence_length']
        )
        val_dataset = OrderBookDataset(
            data=val_data,
            sequence_length=self.config['data']['sequence_length']
        )
        
        train_loader = DataLoader(
            train_dataset,
            batch_size=self.config['training']['batch_size'],
            shuffle=True
        )
        val_loader = DataLoader(
            val_dataset,
            batch_size=self.config['training']['batch_size'],
            shuffle=False
        )
        
        # 单独训练每个基础模型
        for name, model in self.models.items():
            print(f"Training {name}...")
            self._train_single_model(
                model=model,
                train_loader=train_loader,
                val_loader=val_loader,
                model_name=name
            )
        
        # 训练元模型
        print("Training meta model...")
        self._train_meta_model(train_loader, val_loader)
        
    def predict(self, features: np.ndarray) -> Dict:
        """集成预测"""
        predictions = {}
        
        # 获取每个基础模型的预测
        for name, model in self.models.items():
            model.eval()
            with torch.no_grad():
                input_tensor = torch.FloatTensor(features).unsqueeze(0)
                pred = model(input_tensor)
                predictions[name] = pred.item()
        
        # 元模型集成
        meta_input = torch.FloatTensor([list(predictions.values())])
        final_prediction = self.meta_model(meta_input).item()
        
        return {
            'base_predictions': predictions,
            'ensemble_prediction': final_prediction,
            'confidence': self._calculate_confidence(predictions)
        }
    
    def _calculate_confidence(self, predictions: Dict) -> float:
        """计算预测置信度"""
        values = list(predictions.values())
        if len(values) == 0:
            return 0.0
        
        # 基于预测一致性的置信度
        mean_pred = np.mean(values)
        std_pred = np.std(values)
        
        # 标准差越小，置信度越高
        confidence = 1.0 / (1.0 + std_pred)
        
        return min(confidence, 1.0
        


        # trading_system.py
import asyncio
import json
import numpy as np
from typing import Dict, List
from dataclasses import dataclass
from enum import Enum
import pandas as pd
from datetime import datetime, timedelta

class SignalType(Enum):
    """交易信号类型"""
    STRONG_BUY = 4
    BUY = 3
    WEAK_BUY = 2
    NEUTRAL = 1
    WEAK_SELL = -2
    SELL = -3
    STRONG_SELL = -4

@dataclass
class TradingSignal:
    """交易信号"""
    timestamp: datetime
    symbol: str
    signal_type: SignalType
    confidence: float
    predicted_return: float
    features: Dict
    model_predictions: Dict

class TradingSystem:
    """高频交易系统"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.model = None
        self.position_manager = PositionManager(config)
        self.risk_manager = RiskManager(config)
        self.setup_model()
        
    def setup_model(self):
        """加载训练好的模型"""
        from models import HighFrequencyEnsembleModel
        
        self.model = HighFrequencyEnsembleModel(self.config)
        # 加载预训练权重
        self.model.load_state_dict(
            torch.load(self.config['model']['weights_path'])
        )
        self.model.eval()
        
    async def process_realtime_data(self):
        """处理实时数据并生成交易信号"""
        from kafka import KafkaConsumer
        
        # 创建Kafka消费者
        consumer = KafkaConsumer(
            'processed_features',
            bootstrap_servers=self.config['kafka']['bootstrap_servers'],
            value_deserializer=lambda x: json.loads(x.decode('utf-8')),
            auto_offset_reset='latest',
            enable_auto_commit=True
        )
        
        # 滑动窗口缓存
        window_size = self.config['model']['sequence_length']
        data_window = {}
        
        for message in consumer:
            try:
                data = message.value
                symbol = data['symbol']
                
                # 添加到窗口
                if symbol not in data_window:
                    data_window[symbol] = []
                
                data_window[symbol].append(data)
                
                # 保持窗口大小
                if len(data_window[symbol]) > window_size:
                    data_window[symbol] = data_window[symbol][-window_size:]
                
                # 当窗口满时进行预测
                if len(data_window[symbol]) == window_size:
                    signal = await self.generate_signal(symbol, data_window[symbol])
                    
                    if signal and self.should_trade(signal):
                        await self.execute_trade(signal)
                        
            except Exception as e:
                print(f"Error processing message: {e}")
                
    async def generate_signal(self, symbol: str, window_data: List[Dict]) -> TradingSignal:
        """生成交易信号"""
        # 提取特征
        features = self.extract_features(window_data)
        
        # 模型预测
        prediction_result = self.model.predict(features)
        
        # 生成信号
        predicted_return = prediction_result['ensemble_prediction']
        confidence = prediction_result['confidence']
        
        # 根据预测收益和置信度确定信号强度
        signal_type = self._return_to_signal(predicted_return, confidence)
        
        signal = TradingSignal(
            timestamp=datetime.now(),
            symbol=symbol,
            signal_type=signal_type,
            confidence=confidence,
            predicted_return=predicted_return,
            features=features,
            model_predictions=prediction_result['base_predictions']
        )
        
        return signal
    
    def _return_to_signal(self, predicted_return: float, confidence: float) -> SignalType:
        """将预测收益转换为交易信号"""
        threshold = 0.001  # 0.1%收益率阈值
        
        if predicted_return > threshold * 2 and confidence > 0.7:
            return SignalType.STRONG_BUY
        elif predicted_return > threshold and confidence > 0.5:
            return SignalType.BUY
        elif predicted_return > 0 and confidence > 0.3:
            return SignalType.WEAK_BUY
        elif predicted_return < -threshold * 2 and confidence > 0.7:
            return SignalType.STRONG_SELL
        elif predicted_return < -threshold and confidence > 0.5:
            return SignalType.SELL
        elif predicted_return < 0 and confidence > 0.3:
            return SignalType.WEAK_SELL
        else:
            return SignalType.NEUTRAL
    
    def should_trade(self, signal: TradingSignal) -> bool:
        """判断是否应该交易"""
        # 1. 风控检查
        if not self.risk_manager.check_signal(signal):
            return False
            
        # 2. 仓位管理检查
        if not self.position_manager.can_trade(signal):
            return False
            
        # 3. 信号强度检查
        if abs(signal.signal_type.value) < 3:  # 弱信号不交易
            return False
            
        # 4. 置信度检查
        if signal.confidence < 0.6:
            return False
            
        return True
    
    async def execute_trade(self, signal: TradingSignal):
        """执行交易"""
        try:
            # 1. 计算头寸规模
            position_size = self.position_manager.calculate_position_size(signal)
            
            # 2. 创建订单
            order = self.create_order(signal, position_size)
            
            # 3. 执行订单（使用Alpaca API）
            await self.execute_order(order)
            
            # 4. 更新仓位
            self.position_manager.update_position(signal, order)
            
            # 5. 记录交易
            self.log_trade(signal, order)
            
        except Exception as e:
            print(f"Error executing trade: {e}")
            
    def create_order(self, signal: TradingSignal, position_size: float) -> Dict:
        """创建订单"""
        order_type = 'market' if self.config['trading']['use_market_orders'] else 'limit'
        
        if signal.signal_type.value > 0:  # 买入信号
            order_side = 'buy'
            # 对于限价单，可以设置稍微高于当前价的价格
            limit_price = None
            if order_type == 'limit':
                current_price = signal.features.get('best_ask', 0)
                limit_price = current_price * 1.0001  # 高0.01%
                
        else:  # 卖出信号
            order_side = 'sell'
            limit_price = None
            if order_type == 'limit':
                current_price = signal.features.get('best_bid', 0)
                limit_price = current_price * 0.9999  # 低0.01%
        
        return {
            'symbol': signal.symbol,
            'qty': position_size,
            'side': order_side,
            'type': order_type,
            'time_in_force': 'gtc',
            'limit_price': limit_price,
            'stop_price': None,
            'client_order_id': f"{signal.symbol}_{int(signal.timestamp.timestamp())}",
            'signal_data': {
                'predicted_return': signal.predicted_return,
                'confidence': signal.confidence,
                'signal_type': signal.signal_type.name
            }
        }
    
    async def execute_order(self, order: Dict):
        """使用Alpaca执行订单"""
        import alpaca_trade_api as tradeapi
        
        api = tradeapi.REST(
            key_id=self.config['alpaca']['api_key'],
            secret_key=self.config['alpaca']['secret_key'],
            base_url=self.config['alpaca']['base_url']
        )
        
        try:
            # 提交订单
            submitted_order = api.submit_order(
                symbol=order['symbol'],
                qty=order['qty'],
                side=order['side'],
                type=order['type'],
                time_in_force=order['time_in_force'],
                limit_price=order['limit_price'],
                client_order_id=order['client_order_id']
            )
            
            print(f"Order submitted: {submitted_order.id}")
            
            # 监控订单状态
            await self.monitor_order(submitted_order.id)
            
        except Exception as e:
            print(f"Error submitting order: {e}")
            
    def extract_features(self, window_data: List[Dict]) -> np.ndarray:
        """从窗口数据提取特征"""
        features_list = []
        
        for data in window_data:
            # 提取数值特征
            feature_vector = []
            
            # 价格特征
            if 'best_bid' in data:
                feature_vector.append(data['best_bid'])
            if 'best_ask' in data:
                feature_vector.append(data['best_ask'])
            if 'spread' in data:
                feature_vector.append(data['spread'])
            if 'orderbook_imbalance' in data:
                feature_vector.append(data['orderbook_imbalance'])
            if 'mid_price' in data:
                feature_vector.append(data['mid_price'])
                
            # 成交量特征
            if 'total_bid_volume' in data:
                feature_vector.append(data['total_bid_volume'])
            if 'total_ask_volume' in data:
                feature_vector.append(data['total_ask_volume'])
                
            # 深度特征
            for i in range(1, 6):
                key = f'depth_ratio_{i}'
                if key in data:
                    feature_vector.append(data[key])
            
            features_list.append(feature_vector)
        
        # 转换为numpy数组
        return np.array(features_list)

class PositionManager:
    """仓位管理器"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.positions = {}  # 当前持仓
        self.max_position = config['trading']['max_position_size']
        self.max_symbols = config['trading']['max_symbols']
        
    def can_trade(self, signal: TradingSignal) -> bool:
        """检查是否可以交易"""
        symbol = signal.symbol
        
        # 1. 检查是否已达到最大持仓数量
        if len(self.positions) >= self.max_symbols:
            return False
            
        # 2. 检查该标的是否已有持仓
        if symbol in self.positions:
            current_position = self.positions[symbol]['quantity']
            
            # 如果已经有同方向持仓，检查是否超过最大持仓
            if (signal.signal_type.value > 0 and current_position > 0) or \
               (signal.signal_type.value < 0 and current_position < 0):
                if abs(current_position) >= self.max_position:
                    return False
        
        return True
    
    def calculate_position_size(self, signal: TradingSignal) -> float:
        """计算头寸规模"""
        # 基于凯利公式的简化版本
        base_size = self.max_position * 0.1  # 基础头寸为最大持仓的10%
        
        # 根据信号强度和置信度调整
        signal_strength = abs(signal.signal_type.value) / 4.0  # 归一化到[0, 1]
        adjusted_size = base_size * signal_strength * signal.confidence
        
        # 限制最小和最大头寸
        min_size = self.max_position * 0.01  # 最小1%
        max_size = self.max_position * 0.3   # 最大30%
        
        return max(min(adjusted_size, max_size), min_size)
    
    def update_position(self, signal: TradingSignal, order: Dict):
        """更新仓位"""
        symbol = signal.symbol
        order_side = order['side']
        quantity = order['qty']
        
        if symbol not in self.positions:
            self.positions[symbol] = {
                'quantity': 0,
                'avg_price': 0,
                'timestamp': datetime.now()
            }
        
        position = self.positions[symbol]
        
        if order_side == 'buy':
            new_quantity = position['quantity'] + quantity
            # 更新平均价格
            if new_quantity != 0:
                position['avg_price'] = (
                    position['avg_price'] * position['quantity'] + 
                    order.get('avg_fill_price', 0) * quantity
                ) / new_quantity
            position['quantity'] = new_quantity
            
        elif order_side == 'sell':
            new_quantity = position['quantity'] - quantity
            position['quantity'] = new_quantity
            
        position['timestamp'] = datetime.now()
        
        # 如果仓位为0，移除记录
        if position['quantity'] == 0:
            del self.positions[symbol]

class RiskManager:
    """风险管理器"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.daily_pnl = 0
        self.max_daily_loss = config['risk']['max_daily_loss']
        self.max_position_risk = config['risk']['max_position_risk']
        
    def check_signal(self, signal: TradingSignal) -> bool:
        """检查信号是否通过风控"""
        # 1. 检查当日盈亏
        if self.daily_pnl < -self.max_daily_loss:
            print(f"Daily loss limit reached: {self.daily_pnl}")
            return False
            
        # 2. 检查波动率（如果特征中包含）
        if 'realized_volatility' in signal.features:
            vol = signal.features['realized_volatility']
            if vol > self.config['risk']['max_volatility']:
                print(f"Volatility too high: {vol}")
                return False
                
        # 3. 检查预测收益的合理性
        if abs(signal.predicted_return) > self.config['risk']['max_expected_return']:
            print(f"Predicted return too high: {signal.predicted_return}")
            return False
            
        return True
    
    def update_pnl(self, pnl: float):
        """更新当日盈亏"""
        self.daily_pnl += pnl
        
    def reset_daily(self):
        """重置每日统计数据"""
        self.daily_pnl = 0